#!/usr/bin/env python3
"""
Standalone Test fÃ¼r n8n Workflow v2
Simuliert die wichtigsten Nodes lokal
"""

import json
import os
from datetime import datetime

# Test-Daten
test_input = {
    "company": "Apple",
    "ticker": "AAPL",
    "sector": "Technologie",
    "date": "2026-01-18"
}

print("ğŸ§ª n8n Workflow v2 - Standalone Test\n")
print("=" * 60)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1: INPUT VALIDATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n1ï¸âƒ£  Input Validator")
print("-" * 60)

# Pflichtfelder prÃ¼fen
required_fields = ['company', 'ticker']
missing = [f for f in required_fields if f not in test_input or not test_input[f]]
if missing:
    print(f"âŒ Fehlende Pflichtfelder: {', '.join(missing)}")
    exit(1)

# Sector Mapping
sector_map = {
    'tech': 'Technologie',
    'technology': 'Technologie',
    'technologie': 'Technologie',
    'finance': 'Finanzen',
    'healthcare': 'Gesundheit',
}

raw_sector = test_input.get('sector', 'Technologie').lower().strip()
sector = sector_map.get(raw_sector, test_input.get('sector', 'Technologie'))

company = test_input['company'].strip()
ticker = test_input['ticker'].upper().strip()
date = test_input.get('date', datetime.now().strftime('%Y-%m-%d'))
base_dir = '/Users/kevinwaibel/Dokumente/capitovo/Code/capitovo'

# Slug generieren
slug = f"{company}-{ticker}".lower()
slug = slug.replace('Ã¤', 'ae').replace('Ã¶', 'oe').replace('Ã¼', 'ue').replace('ÃŸ', 'ss')
slug = ''.join(c if c.isalnum() else '-' for c in slug)
slug = slug.strip('-')

# Exchange Detection
exchange_map = {
    'AAPL': {'exchange': 'NASDAQ', 'currency': 'USD'},
    'MSFT': {'exchange': 'NASDAQ', 'currency': 'USD'},
    'TSLA': {'exchange': 'NASDAQ', 'currency': 'USD'},
    'SAP': {'exchange': 'XETRA', 'currency': 'EUR'},
}
exchange_info = exchange_map.get(ticker, {'exchange': 'NYSE', 'currency': 'USD'})

validated_data = {
    'company': company,
    'ticker': ticker,
    'sector': sector,
    'date': date,
    'baseDir': base_dir,
    'slug': slug,
    'exchange': exchange_info['exchange'],
    'currency': exchange_info['currency'],
}

print(f"âœ… Company: {company}")
print(f"âœ… Ticker: {ticker}")
print(f"âœ… Sector: {sector}")
print(f"âœ… Exchange: {exchange_info['exchange']}")
print(f"âœ… Currency: {exchange_info['currency']}")
print(f"âœ… Slug: {slug}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2: HISTORY LOADER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n2ï¸âƒ£  History Loader")
print("-" * 60)

previous_analysis = None
history_context = ''

try:
    json_path = os.path.join(base_dir, 'data', 'analysen.json')
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            analysen = json.load(f)
        
        # Suche frÃ¼here Analyse
        previous = next((a for a in analysen 
                        if a.get('id', '').lower().startswith(f"{ticker.lower()}-") 
                        and a.get('date') != date), None)
        
        if previous:
            previous_analysis = {
                'id': previous['id'],
                'date': previous['date'],
                'title': previous.get('title', ''),
                'recommendation': previous.get('recommendation')
            }
            print(f"âœ… FrÃ¼here Analyse gefunden: {previous['id']}")
            print(f"   Datum: {previous['date']}")
            print(f"   Empfehlung: {previous.get('recommendation', 'N/A')}")
        else:
            print("â„¹ï¸  Keine frÃ¼here Analyse gefunden (erste Analyse)")
    else:
        print(f"âš ï¸  analysen.json nicht gefunden: {json_path}")
except Exception as e:
    print(f"âš ï¸  Fehler beim Laden der Historie: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 3: RESEARCH ORCHESTRATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n3ï¸âƒ£  Research Orchestrator")
print("-" * 60)

system_prompt = f"""Du agierst als Senior Equity Research Analyst fÃ¼r einen deutschsprachigen BÃ¶rsenbrief.
SPRACHE: Deutsch
WÃ„HRUNG: {validated_data['currency']}"""

prompts = [
    {'id': 'marketValuation', 'name': 'Marktbewertung', 'length': '150-200 WÃ¶rter'},
    {'id': 'fundamentals', 'name': 'Fundamentaldaten', 'length': '200-250 WÃ¶rter'},
    {'id': 'competition', 'name': 'Wettbewerb', 'length': '200-250 WÃ¶rter'},
    {'id': 'risks', 'name': 'Risiken', 'length': '200-250 WÃ¶rter'},
    {'id': 'thesis', 'name': 'Investment-These', 'length': '250-300 WÃ¶rter'},
]

print(f"âœ… System Prompt erstellt ({len(system_prompt)} Zeichen)")
print(f"âœ… {len(prompts)} spezialisierte Prompts generiert:")
for p in prompts:
    print(f"   - {p['name']} ({p['length']})")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MOCK: Perplexity API Calls
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n4ï¸âƒ£  Perplexity API (MOCK)")
print("-" * 60)
print("âš ï¸  HINWEIS: Echte API-Calls werden hier simuliert")
print(f"   WÃ¼rde 5 parallele Calls zu Perplexity sonar-pro machen")
print(f"   GeschÃ¤tzte Kosten: ~$0.10-0.15")
print()

mock_sections = {
    'marketValuation': f"## Marktbewertung\n\n- **Aktueller Kurs:** 185.50 {validated_data['currency']}\n- **Marktkapitalisierung:** 2.85 Billionen {validated_data['currency']}",
    'fundamentals': "## Fundamentaldaten\n\n| Kennzahl | Wert |\n|----------|------|\n| KGV | 29.5 |",
    'competition': "## Wettbewerb\n\nMarktfÃ¼hrer mit ~58% Marktanteil.",
    'risks': "## Risiken\n\n- Regulatorische Eingriffe\n- China-AbhÃ¤ngigkeit",
    'thesis': f"## Investment-These\n\n**Empfehlung: HALTEN**\n\n**Kursziel:** 210 {validated_data['currency']}"
}

print("âœ… 5 Sektionen generiert (Mock-Daten)")
for section_id, content in mock_sections.items():
    words = len(content.split())
    print(f"   - {section_id}: {words} WÃ¶rter")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 4: QUALITY CHECK
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n6ï¸âƒ£  Quality Check (MOCK)")
print("-" * 60)

quality_score = 8
quality_comment = "Gute Struktur, klare Empfehlung, prÃ¤zise Zahlen."

print(f"âœ… Quality Score: {quality_score}/10")
print(f"âœ… Kommentar: {quality_comment}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 5: FILE OPERATIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n9ï¸âƒ£  File Writer (DRY RUN)")
print("-" * 60)

html_path = os.path.join(base_dir, 'Abonenten', f"{slug}.html")
json_path = os.path.join(base_dir, 'data', 'analysen.json')
svg_path = os.path.join(base_dir, 'data', 'vorschaubilder', f"{slug}.svg")

print(f"ğŸ“„ HTML: {html_path}")
print(f"ğŸ“„ JSON: {json_path}")
print(f"ğŸ“„ SVG: {svg_path}")
print()

# PrÃ¼fe ob Verzeichnisse existieren
html_dir = os.path.dirname(html_path)
svg_dir = os.path.dirname(svg_path)

if os.path.exists(html_dir):
    print(f"âœ… Abonenten/ Verzeichnis existiert")
else:
    print(f"âš ï¸  Abonenten/ Verzeichnis fehlt: {html_dir}")

if os.path.exists(os.path.dirname(json_path)):
    print(f"âœ… data/ Verzeichnis existiert")
else:
    print(f"âš ï¸  data/ Verzeichnis fehlt: {os.path.dirname(json_path)}")

if os.path.exists(svg_dir):
    print(f"âœ… vorschaubilder/ Verzeichnis existiert")
else:
    print(f"âš ï¸  vorschaubilder/ Verzeichnis fehlt - wÃ¼rde erstellt werden")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 60)
print("ğŸ“Š TEST SUMMARY")
print("=" * 60)
print()
print(f"Analyse: {company} ({ticker})")
print(f"Sektor: {sector}")
print(f"Datum: {date}")
print(f"Slug: {slug}")
print(f"Exchange: {validated_data['exchange']}")
print(f"Currency: {validated_data['currency']}")
print()
print(f"Quality Score: {quality_score}/10")
print(f"Empfehlung: HALTEN")
print(f"Kursziel: 210 {validated_data['currency']}")
print()
print("âœ… Alle Validierungen erfolgreich")
print("âœ… 5 Sektionen erstellt")
print("âœ… Quality Gate bestanden (Score â‰¥ 6)")
print()
print("âš ï¸  HINWEIS: Dies ist ein DRY RUN")
print("   FÃ¼r echte Datei-Operationen: n8n Workflow importieren")
print()
print("=" * 60)
